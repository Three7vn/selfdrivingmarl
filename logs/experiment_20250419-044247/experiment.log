2025-04-19 04:42:47,769 - marl_agent - INFO - Starting experiment with config: {'environment': {'env_id': 'highway-v0', 'render_mode': 'human', 'dt': 0.1, 'max_episode_steps': 200, 'observation_type': 'Kinematics', 'vehicles_count': 10}, 'agents': {'num_agents': 2, 'observation_space': {'features': True, 'vehicles_count': 5}, 'action_space': {'discrete': True, 'actions': ['LANE_LEFT', 'IDLE', 'LANE_RIGHT', 'FASTER', 'SLOWER']}}, 'training': {'algorithm': 'VPG', 'learning_rate': 0.0003, 'gamma': 0.99, 'epochs': 500, 'episodes_per_epoch': 10, 'batch_size': 64, 'epsilon_start': 1.0, 'epsilon_end': 0.05, 'epsilon_decay': 0.995}, 'network': {'hidden_layers': [256, 128], 'activation': 'relu'}, 'logging': {'log_interval': 10, 'checkpoint_interval': 50, 'tensorboard': True}}
2025-04-19 04:43:27,058 - marl_agent - INFO - Epoch 0, Episode 0: Rewards=[174.97168635238202, 174.97168635238202]
2025-04-19 04:48:53,943 - marl_agent - INFO - Epoch 0, Episode 9: Rewards=[171.80139206423533, 171.80139206423533]
2025-04-19 04:48:53,947 - marl_agent - INFO - Epoch 0: Mean Rewards=[142.42428163117833, 142.42428163117833], Mean Loss=0.0
2025-04-19 04:49:42,208 - marl_agent - INFO - Epoch 1, Episode 0: Rewards=[185.12343144062189, 185.12343144062189]
